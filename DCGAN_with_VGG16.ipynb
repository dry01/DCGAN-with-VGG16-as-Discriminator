{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ML2ASSINMENT4.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nIcRgzt_GXdo"
      },
      "source": [
        "Dharamvir ramroop yadav MT19CPS012.  ASSIGNMENT Q1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhpeKC9FhUwI"
      },
      "source": [
        "import argparse\n",
        "import os\n",
        "import numpy as np\n",
        "import math\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.utils import save_image\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torch.autograd import Variable\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "from torchvision import datasets, models, transforms"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BI9R07B6HMVK",
        "outputId": "65796107-d16b-4e48-fc19-98293980d5d5"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "or1WWtAmjIet",
        "outputId": "3f4e2697-5dcb-4c19-a7ca-c51b391cda4b"
      },
      "source": [
        "cd /content/drive/MyDrive/ dicom_data/ dcm1"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/ dicom_data/ dcm1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lngGT6UChYT3"
      },
      "source": [
        "os.makedirs(\"images\", exist_ok=True)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJiIH2lUhbc6"
      },
      "source": [
        "def weights_init_normal(m):\n",
        "    classname = m.__class__.__name__\n",
        "    if classname.find(\"Conv\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 0.0, 0.02)\n",
        "    elif classname.find(\"BatchNorm2d\") != -1:\n",
        "        torch.nn.init.normal_(m.weight.data, 1.0, 0.02)\n",
        "        torch.nn.init.constant_(m.bias.data, 0.0)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "izrvrEn-hePW"
      },
      "source": [
        "img_size = 200\n",
        "latent_dim = 100\n",
        "channels = 1\n",
        "batch_size = 32\n",
        "lr = 0.0002\n",
        "n_epochs = 4\n",
        "sample_interval = 500"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8QC_dS7GhHT"
      },
      "source": [
        "VGG-16 model: \n",
        "refer from one of the youtube video"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ws4CPNk_hhjd"
      },
      "source": [
        "VGG_types = {\n",
        "    \"VGG11\": [64, \"M\", 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
        "    \"VGG13\": [64, 64, \"M\", 128, 128, \"M\", 256, 256, \"M\", 512, 512, \"M\", 512, 512, \"M\"],\n",
        "    \"VGG16\": [\n",
        "        64,\n",
        "        64,\n",
        "        \"M\",\n",
        "        128,\n",
        "        128,\n",
        "        \"M\",\n",
        "        256,\n",
        "        256,\n",
        "        256,\n",
        "        \"M\",\n",
        "        512,\n",
        "        512,\n",
        "        512,\n",
        "        \"M\",\n",
        "        512,\n",
        "        512,\n",
        "        512,\n",
        "        \"M\",\n",
        "    ],\n",
        "    \"VGG19\": [\n",
        "        64,\n",
        "        64,\n",
        "        \"M\",\n",
        "        128,\n",
        "        128,\n",
        "        \"M\",\n",
        "        256,\n",
        "        256,\n",
        "        256,\n",
        "        256,\n",
        "        \"M\",\n",
        "        512,\n",
        "        512,\n",
        "        512,\n",
        "        512,\n",
        "        \"M\",\n",
        "        512,\n",
        "        512,\n",
        "        512,\n",
        "        512,\n",
        "        \"M\",\n",
        "    ],\n",
        "}\n",
        "\n",
        "\n",
        "class VGG_net(nn.Module):\n",
        "    def __init__(self, in_channels=1, num_classes=1):\n",
        "        super(VGG_net, self).__init__()\n",
        "        self.in_channels = in_channels\n",
        "        self.conv_layers = self.create_conv_layers(VGG_types[\"VGG16\"])\n",
        "\n",
        "        self.fcs = nn.Sequential(\n",
        "            nn.Linear(512 * 7 * 7, 4096),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(4096, 100),\n",
        "            nn.ReLU(),\n",
        "            nn.Dropout(p=0.5),\n",
        "            nn.Linear(100, num_classes),\n",
        "            nn.Sigmoid()\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_layers(x)\n",
        "        x = x.reshape(x.shape[0], -1)\n",
        "        x = self.fcs(x)\n",
        "        return x\n",
        "\n",
        "    def create_conv_layers(self, architecture):\n",
        "        layers = []\n",
        "        in_channels = self.in_channels\n",
        "\n",
        "        for x in architecture:\n",
        "            if type(x) == int:\n",
        "                out_channels = x\n",
        "\n",
        "                layers += [\n",
        "                    nn.Conv2d(\n",
        "                        in_channels=in_channels,\n",
        "                        out_channels=out_channels,\n",
        "                        kernel_size=(3, 3),\n",
        "                        stride=(1, 1),\n",
        "                        padding=(1, 1),\n",
        "                    ),\n",
        "                    nn.BatchNorm2d(x),\n",
        "                    nn.ReLU(),\n",
        "                ]\n",
        "                in_channels = x\n",
        "            elif x == \"M\":\n",
        "                layers += [nn.MaxPool2d(kernel_size=(2, 2), stride=(2, 2))]\n",
        "\n",
        "        return nn.Sequential(*layers)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CyNfXNPmGusX"
      },
      "source": [
        "Generator part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dA_XIjNGhpgj"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Generator, self).__init__()\n",
        "\n",
        "        self.init_size = img_size // 4\n",
        "        self.l1 = nn.Sequential(nn.Linear(latent_dim, 128 * self.init_size ** 2))\n",
        "\n",
        "        self.conv_blocks = nn.Sequential(\n",
        "            nn.BatchNorm2d(128),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 128, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(128, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Upsample(scale_factor=2),\n",
        "            nn.Conv2d(128, 64, 3, stride=1, padding=1),\n",
        "            nn.BatchNorm2d(64, 0.8),\n",
        "            nn.LeakyReLU(0.2, inplace=True),\n",
        "            nn.Conv2d(64, channels, 3, stride=1, padding=1),\n",
        "            nn.Tanh(),\n",
        "        )\n",
        "\n",
        "    def forward(self, z):\n",
        "        out = self.l1(z)\n",
        "        out = out.view(out.shape[0], 128, self.init_size, self.init_size)\n",
        "        img = self.conv_blocks(out)\n",
        "        return img"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oawG_SR0ht5Y"
      },
      "source": [
        "cuda = True if torch.cuda.is_available() else False"
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVuqJz1ChyHI"
      },
      "source": [
        "# Loss function\n",
        "adversarial_loss = torch.nn.BCELoss()\n",
        "\n",
        "# Initialize generator and discriminator\n",
        "generator = Generator()\n",
        "#discriminator = Discriminator()\n",
        "#discriminator = vgg16\n",
        "discriminator = VGG_net()\n",
        "if cuda:\n",
        "    generator.cuda()\n",
        "    discriminator.cuda()\n",
        "    adversarial_loss.cuda()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wrHWZd0oh2Cm"
      },
      "source": [
        "generator.apply(weights_init_normal)\n",
        "discriminator.apply(weights_init_normal)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKr0nKqvi10B"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p84pAiNcGyLb"
      },
      "source": [
        "MNIST datasets loading"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2mkxJQ3Nh5I6"
      },
      "source": [
        "os.makedirs(\"../../data/mnist\", exist_ok=True)\n",
        "dataloader = torch.utils.data.DataLoader(\n",
        "    datasets.MNIST(\n",
        "        \"../../data/mnist\",\n",
        "        train=True,\n",
        "        download=True,\n",
        "        transform=transforms.Compose(\n",
        "            [transforms.Resize(img_size), transforms.ToTensor(), transforms.Normalize([0.5], [0.5])]\n",
        "        ),\n",
        "    ),\n",
        "    batch_size=batch_size,\n",
        "    shuffle=True,\n",
        "    num_workers = 40\n",
        ")"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnUKW6C5h9wa"
      },
      "source": [
        "optimizer_G = torch.optim.Adam(generator.parameters(), lr=lr, betas=(0.5, 0.999))\n",
        "optimizer_D = torch.optim.Adam(discriminator.parameters(), lr=lr, betas=(0.5, 0.999))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b_nmbhp6iBeJ"
      },
      "source": [
        "Tensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUWMTqa5G1b9"
      },
      "source": [
        "training part"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_zkXriXpiE5-"
      },
      "source": [
        "gen_loss = []\n",
        "dis_loss = []\n",
        "for epoch in range(n_epochs):\n",
        "    for i, (imgs, _) in enumerate(dataloader):\n",
        "\n",
        "        # Adversarial ground truths\n",
        "        valid = Variable(Tensor(imgs.shape[0], 1).fill_(1.0), requires_grad=False)\n",
        "        fake = Variable(Tensor(imgs.shape[0], 1).fill_(0.0), requires_grad=False)\n",
        "\n",
        "        # Configure input\n",
        "        real_imgs = Variable(imgs.type(Tensor))\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "\n",
        "        optimizer_G.zero_grad()\n",
        "\n",
        "        # Sample noise as generator input\n",
        "        z = Variable(Tensor(np.random.normal(0, 1, (imgs.shape[0], latent_dim))))\n",
        "\n",
        "        # Generate a batch of images\n",
        "        gen_imgs = generator(z)\n",
        "\n",
        "        # Loss measures generator's ability to fool the discriminator\n",
        "        g_loss = adversarial_loss(discriminator(gen_imgs), valid)\n",
        "\n",
        "        g_loss.backward()\n",
        "\n",
        "        optimizer_G.step()\n",
        "        gen_loss.append(g_loss.item())\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "\n",
        "        optimizer_D.zero_grad()\n",
        "\n",
        "        # Measure discriminator's ability to classify real from generated samples\n",
        "        real_loss = adversarial_loss(discriminator(real_imgs), valid)\n",
        "        fake_loss = adversarial_loss(discriminator(gen_imgs.detach()), fake)\n",
        "        d_loss = (real_loss + fake_loss) / 2\n",
        "\n",
        "        d_loss.backward()\n",
        "        dis_loss.append(d_loss.item())\n",
        "        optimizer_D.step()\n",
        "\n",
        "        print(\n",
        "            \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f]\"\n",
        "            % (epoch, n_epochs, i, len(dataloader), d_loss.item(), g_loss.item())\n",
        "        )\n",
        "\n",
        "        batches_done = epoch * len(dataloader) + i\n",
        "        if batches_done % sample_interval == 0:\n",
        "            save_image(gen_imgs.data[:25], \"images/%d.png\" % batches_done, nrow=5, normalize=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ru0kSxAoiM6s"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(gen_loss)\n",
        "plt.plot(dis_loss)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SrP_vN-hqIPv"
      },
      "source": [
        "from IPython.display import Image\n",
        "Image('/content/drive/MyDrive/ dicom_data/ dcm1/images/1500.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Y8tKD-DqQ4C"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}